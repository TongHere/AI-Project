{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Fiftyone Dataset"
      ],
      "metadata": {
        "id": "Uw5I_ipwJmsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "V1IWP6CqGDnY",
        "outputId": "3ee0035a-10af-4449-e914-3056ab536eb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fiftyone\n",
            "  Downloading fiftyone-0.18.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 4.8 MB/s \n",
            "\u001b[?25hCollecting mongoengine==0.24.2\n",
            "  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 60.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.16.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.8.10)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from fiftyone) (6.0)\n",
            "Collecting dacite>=1.6.0\n",
            "  Downloading dacite-1.6.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from fiftyone) (21.3)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from fiftyone) (0.18.3)\n",
            "Collecting motor>=2.3\n",
            "  Downloading motor-3.1.1-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.5 MB/s \n",
            "\u001b[?25hCollecting sseclient-py<2,>=1.7.2\n",
            "  Downloading sseclient_py-1.7.2-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from fiftyone) (2022.6)\n",
            "Requirement already satisfied: pymongo>=3.11 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (4.3.2)\n",
            "Collecting hypercorn>=0.13.2\n",
            "  Downloading Hypercorn-0.14.3-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (7.1.2)\n",
            "Collecting fiftyone-brain<0.10,>=0.9.2\n",
            "  Downloading fiftyone_brain-0.9.2-py3-none-any.whl (49 kB)\n",
            "\u001b[K     |████████████████████████████████| 49 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Collecting aiofiles\n",
            "  Downloading aiofiles-22.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting kaleido\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 79.9 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.5.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.3.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from fiftyone) (1.0.2)\n",
            "Collecting strawberry-graphql==0.138.1\n",
            "  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n",
            "\u001b[K     |████████████████████████████████| 192 kB 51.4 MB/s \n",
            "\u001b[?25hCollecting voxel51-eta<0.9,>=0.8.1\n",
            "  Downloading voxel51_eta-0.8.1-py2.py3-none-any.whl (564 kB)\n",
            "\u001b[K     |████████████████████████████████| 564 kB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiftyone) (57.4.0)\n",
            "Collecting Deprecated\n",
            "  Downloading Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.7/dist-packages (from fiftyone) (4.6.0.66)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from fiftyone) (5.4.8)\n",
            "Collecting argcomplete\n",
            "  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\n",
            "Collecting pprintpp\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.26.13-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 63.0 MB/s \n",
            "\u001b[?25hCollecting fiftyone-db<0.5,>=0.4\n",
            "  Downloading fiftyone_db-0.4.0-py3-none-manylinux1_x86_64.whl (37.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 37.8 MB 1.3 MB/s \n",
            "\u001b[?25hCollecting ndjson\n",
            "  Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fiftyone) (3.2.2)\n",
            "Collecting retrying\n",
            "  Downloading retrying-1.3.3.tar.gz (10 kB)\n",
            "Collecting Jinja2>=3\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[K     |████████████████████████████████| 133 kB 62.8 MB/s \n",
            "\u001b[?25hCollecting starlette==0.20.4\n",
            "  Downloading starlette-0.20.4-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting eventlet\n",
            "  Downloading eventlet-0.33.2-py2.py3-none-any.whl (226 kB)\n",
            "\u001b[K     |████████████████████████████████| 226 kB 56.6 MB/s \n",
            "\u001b[?25hCollecting anyio<5,>=3.4.0\n",
            "  Downloading anyio-3.6.2-py3-none-any.whl (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.10.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.20.4->fiftyone) (4.1.1)\n",
            "Collecting graphql-core<3.3.0,>=3.2.0\n",
            "  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n",
            "\u001b[K     |████████████████████████████████| 202 kB 55.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.7/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n",
            "Collecting backports.cached-property<2.0.0,>=1.0.2\n",
            "  Downloading backports.cached_property-1.0.2-py3-none-any.whl (6.1 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fiftyone) (2.10)\n",
            "Collecting sniffio>=1.1\n",
            "  Downloading sniffio-1.3.0-py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from fiftyone-brain<0.10,>=0.9.2->fiftyone) (1.7.3)\n",
            "Collecting typing-extensions>=3.10.0\n",
            "  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting priority\n",
            "  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Collecting h2>=3.1.0\n",
            "  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.10.2)\n",
            "Collecting h11\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting wsproto>=0.14.0\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting hpack<5,>=4.0\n",
            "  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n",
            "Collecting hyperframe<7,>=6.0\n",
            "  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=3->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (8.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from plotly>=4.14->fiftyone) (1.15.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from pymongo>=3.11->fiftyone) (2.2.1)\n",
            "Collecting httpx>=0.10.0\n",
            "  Downloading httpx-0.23.1-py3-none-any.whl (84 kB)\n",
            "\u001b[K     |████████████████████████████████| 84 kB 4.0 MB/s \n",
            "\u001b[?25hCollecting httpcore<0.17.0,>=0.15.0\n",
            "  Downloading httpcore-0.16.1-py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2022.9.24)\n",
            "Collecting rfc3986[idna2008]<2,>=1.3\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.3.6)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.5.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (1.24.3)\n",
            "Collecting patool\n",
            "  Downloading patool-1.12-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 6.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (4.13.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.23.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from voxel51-eta<0.9,>=0.8.1->fiftyone) (2.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->voxel51-eta<0.9,>=0.8.1->fiftyone) (3.10.0)\n",
            "Collecting botocore<1.30.0,>=1.29.13\n",
            "  Downloading botocore-1.29.13-py3-none-any.whl (9.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 9.9 MB 30.3 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.7.0,>=0.6.0\n",
            "  Downloading s3transfer-0.6.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.2 MB/s \n",
            "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from Deprecated->fiftyone) (1.14.1)\n",
            "Requirement already satisfied: greenlet>=0.3 in /usr/local/lib/python3.7/dist-packages (from eventlet->fiftyone) (2.0.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fiftyone) (3.0.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->voxel51-eta<0.9,>=0.8.1->fiftyone) (3.0.4)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 54.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (1.3.0)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2.9.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->fiftyone) (2021.11.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->fiftyone) (1.2.0)\n",
            "Building wheels for collected packages: retrying\n",
            "  Building wheel for retrying (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for retrying: filename=retrying-1.3.3-py3-none-any.whl size=11448 sha256=ce9ffbbd7e35d283d1f121b8ef3da0538b9191646dd4e78e3c37a5c54eee6fa5\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/8d/8d/f6af3f7f9eea3553bc2fe6d53e4b287dad18b06a861ac56ddf\n",
            "Successfully built retrying\n",
            "Installing collected packages: typing-extensions, sniffio, urllib3, rfc3986, jmespath, h11, anyio, hyperframe, httpcore, hpack, botocore, wsproto, starlette, s3transfer, retrying, priority, patool, ndjson, httpx, h2, graphql-core, backports.cached-property, argcomplete, xmltodict, voxel51-eta, universal-analytics-python3, strawberry-graphql, sseclient-py, sse-starlette, pprintpp, motor, mongoengine, kaleido, Jinja2, hypercorn, fiftyone-db, fiftyone-brain, eventlet, Deprecated, dacite, boto3, aiofiles, fiftyone\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.1.1\n",
            "    Uninstalling typing-extensions-4.1.1:\n",
            "      Successfully uninstalled typing-extensions-4.1.1\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: Jinja2\n",
            "    Found existing installation: Jinja2 2.11.3\n",
            "    Uninstalling Jinja2-2.11.3:\n",
            "      Successfully uninstalled Jinja2-2.11.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.1.5 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "spacy 3.4.2 requires typing-extensions<4.2.0,>=3.7.4; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\n",
            "notebook 5.7.16 requires jinja2<=3.0.0, but you have jinja2 3.1.2 which is incompatible.\n",
            "flask 1.1.4 requires Jinja2<3.0,>=2.10.1, but you have jinja2 3.1.2 which is incompatible.\n",
            "confection 0.0.3 requires typing-extensions<4.2.0,>=3.7.4.1; python_version < \"3.8\", but you have typing-extensions 4.4.0 which is incompatible.\u001b[0m\n",
            "Successfully installed Deprecated-1.2.13 Jinja2-3.1.2 aiofiles-22.1.0 anyio-3.6.2 argcomplete-2.0.0 backports.cached-property-1.0.2 boto3-1.26.13 botocore-1.29.13 dacite-1.6.0 eventlet-0.33.2 fiftyone-0.18.0 fiftyone-brain-0.9.2 fiftyone-db-0.4.0 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-0.16.1 httpx-0.23.1 hypercorn-0.14.3 hyperframe-6.0.1 jmespath-1.0.1 kaleido-0.2.1 mongoengine-0.24.2 motor-3.1.1 ndjson-0.3.1 patool-1.12 pprintpp-0.4.0 priority-2.0.0 retrying-1.3.3 rfc3986-1.5.0 s3transfer-0.6.0 sniffio-1.3.0 sse-starlette-0.10.3 sseclient-py-1.7.2 starlette-0.20.4 strawberry-graphql-0.138.1 typing-extensions-4.4.0 universal-analytics-python3-1.1.1 urllib3-1.25.11 voxel51-eta-0.8.1 wsproto-1.2.0 xmltodict-0.13.0\n",
            "Migrating database to v0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.migrations.runner:Migrating database to v0.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['activitynet-100', 'activitynet-200', 'bdd100k', 'caltech101', 'caltech256', 'cifar10', 'cifar100', 'cityscapes', 'coco-2014', 'coco-2017', 'fashion-mnist', 'fiw', 'hmdb51', 'imagenet-2012', 'imagenet-sample', 'kinetics-400', 'kinetics-600', 'kinetics-700', 'kinetics-700-2020', 'kitti', 'kitti-multiview', 'lfw', 'mnist', 'open-images-v6', 'quickstart', 'quickstart-geo', 'quickstart-groups', 'quickstart-video', 'ucf101', 'voc-2007', 'voc-2012']\n",
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [2.5s elapsed, 0s remaining, 738.6Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [2.5s elapsed, 0s remaining, 738.6Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    6.1Gb/6.1Gb [8.1s elapsed, 0s remaining, 761.8Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    6.1Gb/6.1Gb [8.1s elapsed, 0s remaining, 761.8Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 5000/5000 [48.4s elapsed, 0s remaining, 109.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 5000/5000 [48.4s elapsed, 0s remaining, 109.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation' created\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "\n",
              "@import url(\"https://fonts.googleapis.com/css2?family=Palanquin&display=swap\");\n",
              "\n",
              "#focontainer-b36b9551-814e-48fe-945c-d30654485588 {\n",
              "  position: relative;\n",
              "  height: px;\n",
              "  display: block !important;\n",
              "}\n",
              "#foactivate-b36b9551-814e-48fe-945c-d30654485588 {\n",
              "  font-weight: bold;\n",
              "  cursor: pointer;\n",
              "  font-size: 24px;\n",
              "  border-radius: 3px;\n",
              "  text-align: center;\n",
              "  padding: 0.5em;\n",
              "  color: rgb(255, 255, 255);\n",
              "  font-family: \"Palanquin\", sans-serif;\n",
              "  position: absolute;\n",
              "  left: 50%;\n",
              "  top: 50%;\n",
              "  width: 160px;\n",
              "  margin-left: -80px;\n",
              "  margin-top: -23px;\n",
              "  background: hsla(210,11%,15%, 0.8);\n",
              "  border: none;\n",
              "}\n",
              "#foactivate-b36b9551-814e-48fe-945c-d30654485588:focus {\n",
              "  outline: none;\n",
              "}\n",
              "#fooverlay-b36b9551-814e-48fe-945c-d30654485588 {\n",
              "  width: 100%;\n",
              "  height: 100%;\n",
              "  background: hsla(208, 7%, 46%, 0.7);\n",
              "  position: absolute;\n",
              "  top: 0;\n",
              "  left: 0;\n",
              "  display: none;\n",
              "  cursor: pointer;\n",
              "}\n",
              "</style>\n",
              "<div id=\"focontainer-b36b9551-814e-48fe-945c-d30654485588\" style=\"display: none;\">\n",
              "   <div id=\"fooverlay-b36b9551-814e-48fe-945c-d30654485588\">\n",
              "      <button id=\"foactivate-b36b9551-814e-48fe-945c-d30654485588\" >Activate</button>\n",
              "   </div>\n",
              "</div>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "! pip install fiftyone\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "\n",
        "# List available zoo datasets\n",
        "print(foz.list_zoo_datasets())\n",
        "\n",
        "#\n",
        "# Load the COCO-2017 validation split into a FiftyOne dataset\n",
        "#\n",
        "# This will download the dataset from the web, if necessary\n",
        "#\n",
        "dataset = foz.load_zoo_dataset(\"coco-2017\", split=\"validation\")\n",
        "\n",
        "# Give the dataset a new name, and make it persistent so that you can\n",
        "# work with it in future sessions\n",
        "dataset.name = \"coco-2017-validation-example\"\n",
        "dataset.persistent = True\n",
        "\n",
        "# Visualize the in the App\n",
        "session = fo.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CtiyScape"
      ],
      "metadata": {
        "id": "XyBntHfmJqxg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install cityscapesscripts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "5C92cXveJchl",
        "outputId": "f8ff4ffd-df24-4e4d-b12a-3c320313af87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cityscapesscripts\n",
            "  Downloading cityscapesScripts-2.2.1-py3-none-any.whl (473 kB)\n",
            "\u001b[K     |████████████████████████████████| 473 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts) (3.2.2)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts) (4.64.1)\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.9 MB/s \n",
            "\u001b[?25hCollecting pyquaternion\n",
            "  Downloading pyquaternion-0.9.9-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts) (1.4.4)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->cityscapesscripts) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->cityscapesscripts) (1.15.0)\n",
            "Building wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26323 sha256=a81300ef0456a5dc68de9152775700ac9084933f5f148bd8549b8afba900483b\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built typing\n",
            "Installing collected packages: humanfriendly, typing, pyquaternion, coloredlogs, cityscapesscripts\n",
            "Successfully installed cityscapesscripts-2.2.1 coloredlogs-15.0.1 humanfriendly-10.0 pyquaternion-0.9.9 typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install cityscapesscripts[gui]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op7kDbwIJete",
        "outputId": "02006490-4e12-4aee-c086-1bf633bb257d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: cityscapesscripts[gui] in /usr/local/lib/python3.7/dist-packages (2.2.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (7.1.2)\n",
            "Requirement already satisfied: pyquaternion in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (0.9.9)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (3.2.2)\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (3.7.4.3)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (1.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (4.64.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.7/dist-packages (from cityscapesscripts[gui]) (15.0.1)\n",
            "Collecting PyQt5\n",
            "  Downloading PyQt5-5.15.7-cp37-abi3-manylinux1_x86_64.whl (8.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.4 MB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.7/dist-packages (from coloredlogs->cityscapesscripts[gui]) (10.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts[gui]) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts[gui]) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts[gui]) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cityscapesscripts[gui]) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->cityscapesscripts[gui]) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->cityscapesscripts[gui]) (1.15.0)\n",
            "Collecting PyQt5-sip<13,>=12.11\n",
            "  Downloading PyQt5_sip-12.11.0-cp37-cp37m-manylinux1_x86_64.whl (344 kB)\n",
            "\u001b[K     |████████████████████████████████| 344 kB 49.6 MB/s \n",
            "\u001b[?25hCollecting PyQt5-Qt5>=5.15.0\n",
            "  Downloading PyQt5_Qt5-5.15.2-py3-none-manylinux2014_x86_64.whl (59.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 59.9 MB 1.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: PyQt5-sip, PyQt5-Qt5, PyQt5\n",
            "Successfully installed PyQt5-5.15.7 PyQt5-Qt5-5.15.2 PyQt5-sip-12.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function, absolute_import, division\n",
        "from collections import namedtuple\n"
      ],
      "metadata": {
        "id": "rc3obgYlLW8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Label = namedtuple( 'Label' , [\n",
        "\n",
        "    'name'        , # The identifier of this label, e.g. 'car', 'person', ... .\n",
        "                    # We use them to uniquely name a class\n",
        "\n",
        "    'id'          , # An integer ID that is associated with this label.\n",
        "                    # The IDs are used to represent the label in ground truth images\n",
        "                    # An ID of -1 means that this label does not have an ID and thus\n",
        "                    # is ignored when creating ground truth images (e.g. license plate).\n",
        "                    # Do not modify these IDs, since exactly these IDs are expected by the\n",
        "                    # evaluation server.\n",
        "\n",
        "    'trainId'     , # Feel free to modify these IDs as suitable for your method. Then create\n",
        "                    # ground truth images with train IDs, using the tools provided in the\n",
        "                    # 'preparation' folder. However, make sure to validate or submit results\n",
        "                    # to our evaluation server using the regular IDs above!\n",
        "                    # For trainIds, multiple labels might have the same ID. Then, these labels\n",
        "                    # are mapped to the same class in the ground truth images. For the inverse\n",
        "                    # mapping, we use the label that is defined first in the list below.\n",
        "                    # For example, mapping all void-type classes to the same ID in training,\n",
        "                    # might make sense for some approaches.\n",
        "                    # Max value is 255!\n",
        "\n",
        "    'category'    , # The name of the category that this label belongs to\n",
        "\n",
        "    'categoryId'  , # The ID of this category. Used to create ground truth images\n",
        "                    # on category level.\n",
        "\n",
        "    'hasInstances', # Whether this label distinguishes between single instances or not\n",
        "\n",
        "    'ignoreInEval', # Whether pixels having this class as ground truth label are ignored\n",
        "                    # during evaluations or not\n",
        "\n",
        "    'color'       , # The color of this label\n",
        "    ] )"
      ],
      "metadata": {
        "id": "ysI2Xub5LgDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# A list of all labels\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Please adapt the train IDs as appropriate for your approach.\n",
        "# Note that you might want to ignore labels with ID 255 during training.\n",
        "# Further note that the current train IDs are only a suggestion. You can use whatever you like.\n",
        "# Make sure to provide your results using the original IDs and not the training IDs.\n",
        "# Note that many IDs are ignored in evaluation and thus you never need to predict these!\n",
        "\n",
        "labels = [\n",
        "    #       name                     id    trainId   category            catId     hasInstances   ignoreInEval   color\n",
        "    Label(  'unlabeled'            ,  0 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'ego vehicle'          ,  1 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'rectification border' ,  2 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'out of roi'           ,  3 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'static'               ,  4 ,      255 , 'void'            , 0       , False        , True         , (  0,  0,  0) ),\n",
        "    Label(  'dynamic'              ,  5 ,      255 , 'void'            , 0       , False        , True         , (111, 74,  0) ),\n",
        "    Label(  'ground'               ,  6 ,      255 , 'void'            , 0       , False        , True         , ( 81,  0, 81) ),\n",
        "    Label(  'road'                 ,  7 ,        0 , 'flat'            , 1       , False        , False        , (128, 64,128) ),\n",
        "    Label(  'sidewalk'             ,  8 ,        1 , 'flat'            , 1       , False        , False        , (244, 35,232) ),\n",
        "    Label(  'parking'              ,  9 ,      255 , 'flat'            , 1       , False        , True         , (250,170,160) ),\n",
        "    Label(  'rail track'           , 10 ,      255 , 'flat'            , 1       , False        , True         , (230,150,140) ),\n",
        "    Label(  'building'             , 11 ,        2 , 'construction'    , 2       , False        , False        , ( 70, 70, 70) ),\n",
        "    Label(  'wall'                 , 12 ,        3 , 'construction'    , 2       , False        , False        , (102,102,156) ),\n",
        "    Label(  'fence'                , 13 ,        4 , 'construction'    , 2       , False        , False        , (190,153,153) ),\n",
        "    Label(  'guard rail'           , 14 ,      255 , 'construction'    , 2       , False        , True         , (180,165,180) ),\n",
        "    Label(  'bridge'               , 15 ,      255 , 'construction'    , 2       , False        , True         , (150,100,100) ),\n",
        "    Label(  'tunnel'               , 16 ,      255 , 'construction'    , 2       , False        , True         , (150,120, 90) ),\n",
        "    Label(  'pole'                 , 17 ,        5 , 'object'          , 3       , False        , False        , (153,153,153) ),\n",
        "    Label(  'polegroup'            , 18 ,      255 , 'object'          , 3       , False        , True         , (153,153,153) ),\n",
        "    Label(  'traffic light'        , 19 ,        6 , 'object'          , 3       , False        , False        , (250,170, 30) ),\n",
        "    Label(  'traffic sign'         , 20 ,        7 , 'object'          , 3       , False        , False        , (220,220,  0) ),\n",
        "    Label(  'vegetation'           , 21 ,        8 , 'nature'          , 4       , False        , False        , (107,142, 35) ),\n",
        "    Label(  'terrain'              , 22 ,        9 , 'nature'          , 4       , False        , False        , (152,251,152) ),\n",
        "    Label(  'sky'                  , 23 ,       10 , 'sky'             , 5       , False        , False        , ( 70,130,180) ),\n",
        "    Label(  'person'               , 24 ,       11 , 'human'           , 6       , True         , False        , (220, 20, 60) ),\n",
        "    Label(  'rider'                , 25 ,       12 , 'human'           , 6       , True         , False        , (255,  0,  0) ),\n",
        "    Label(  'car'                  , 26 ,       13 , 'vehicle'         , 7       , True         , False        , (  0,  0,142) ),\n",
        "    Label(  'truck'                , 27 ,       14 , 'vehicle'         , 7       , True         , False        , (  0,  0, 70) ),\n",
        "    Label(  'bus'                  , 28 ,       15 , 'vehicle'         , 7       , True         , False        , (  0, 60,100) ),\n",
        "    Label(  'caravan'              , 29 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0, 90) ),\n",
        "    Label(  'trailer'              , 30 ,      255 , 'vehicle'         , 7       , True         , True         , (  0,  0,110) ),\n",
        "    Label(  'train'                , 31 ,       16 , 'vehicle'         , 7       , True         , False        , (  0, 80,100) ),\n",
        "    Label(  'motorcycle'           , 32 ,       17 , 'vehicle'         , 7       , True         , False        , (  0,  0,230) ),\n",
        "    Label(  'bicycle'              , 33 ,       18 , 'vehicle'         , 7       , True         , False        , (119, 11, 32) ),\n",
        "    Label(  'license plate'        , -1 ,       -1 , 'vehicle'         , 7       , False        , True         , (  0,  0,142) ),\n",
        "]\n",
        "\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# Create dictionaries for a fast lookup\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# Please refer to the main method below for example usages!\n",
        "\n",
        "# name to label object\n",
        "name2label      = { label.name    : label for label in labels           }\n",
        "# id to label object\n",
        "id2label        = { label.id      : label for label in labels           }\n",
        "# trainId to label object\n",
        "trainId2label   = { label.trainId : label for label in reversed(labels) }\n",
        "# category to list of label objects\n",
        "category2labels = {}\n",
        "for label in labels:\n",
        "    category = label.category\n",
        "    if category in category2labels:\n",
        "        category2labels[category].append(label)\n",
        "    else:\n",
        "        category2labels[category] = [label]\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# Assure single instance name\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# returns the label name that describes a single instance (if possible)\n",
        "# e.g.     input     |   output\n",
        "#        ----------------------\n",
        "#          car       |   car\n",
        "#          cargroup  |   car\n",
        "#          foo       |   None\n",
        "#          foogroup  |   None\n",
        "#          skygroup  |   None\n",
        "def assureSingleInstanceName( name ):\n",
        "    # if the name is known, it is not a group\n",
        "    if name in name2label:\n",
        "        return name\n",
        "    # test if the name actually denotes a group\n",
        "    if not name.endswith(\"group\"):\n",
        "        return None\n",
        "    # remove group\n",
        "    name = name[:-len(\"group\")]\n",
        "    # test if the new name exists\n",
        "    if not name in name2label:\n",
        "        return None\n",
        "    # test if the new name denotes a label that actually has instances\n",
        "    if not name2label[name].hasInstances:\n",
        "        return None\n",
        "    # all good then\n",
        "    return name\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "# Main for testing\n",
        "#--------------------------------------------------------------------------------\n",
        "\n",
        "# just a dummy main\n",
        "if __name__ == \"__main__\":\n",
        "    # Print all the labels\n",
        "    print(\"List of cityscapes labels:\")\n",
        "    print(\"\")\n",
        "    print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( 'name', 'id', 'trainId', 'category', 'categoryId', 'hasInstances', 'ignoreInEval' ))\n",
        "    print(\"    \" + ('-' * 98))\n",
        "    for label in labels:\n",
        "        print(\"    {:>21} | {:>3} | {:>7} | {:>14} | {:>10} | {:>12} | {:>12}\".format( label.name, label.id, label.trainId, label.category, label.categoryId, label.hasInstances, label.ignoreInEval ))\n",
        "    print(\"\")\n",
        "\n",
        "    print(\"Example usages:\")\n",
        "\n",
        "    # Map from name to label\n",
        "    name = 'car'\n",
        "    id   = name2label[name].id\n",
        "    print(\"ID of label '{name}': {id}\".format( name=name, id=id ))\n",
        "\n",
        "    # Map from ID to label\n",
        "    category = id2label[id].category\n",
        "    print(\"Category of label with ID '{id}': {category}\".format( id=id, category=category ))\n",
        "\n",
        "    # Map from trainID to label\n",
        "    trainId = 0\n",
        "    name = trainId2label[trainId].name\n",
        "    print(\"Name of label with trainID '{id}': {name}\".format( id=trainId, name=name ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kEkLQU7Lh9w",
        "outputId": "8503a50b-2599-4829-a79c-37b70fa5b935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "List of cityscapes labels:\n",
            "\n",
            "                     name |  id | trainId |       category | categoryId | hasInstances | ignoreInEval\n",
            "    --------------------------------------------------------------------------------------------------\n",
            "                unlabeled |   0 |     255 |           void |          0 |            0 |            1\n",
            "              ego vehicle |   1 |     255 |           void |          0 |            0 |            1\n",
            "     rectification border |   2 |     255 |           void |          0 |            0 |            1\n",
            "               out of roi |   3 |     255 |           void |          0 |            0 |            1\n",
            "                   static |   4 |     255 |           void |          0 |            0 |            1\n",
            "                  dynamic |   5 |     255 |           void |          0 |            0 |            1\n",
            "                   ground |   6 |     255 |           void |          0 |            0 |            1\n",
            "                     road |   7 |       0 |           flat |          1 |            0 |            0\n",
            "                 sidewalk |   8 |       1 |           flat |          1 |            0 |            0\n",
            "                  parking |   9 |     255 |           flat |          1 |            0 |            1\n",
            "               rail track |  10 |     255 |           flat |          1 |            0 |            1\n",
            "                 building |  11 |       2 |   construction |          2 |            0 |            0\n",
            "                     wall |  12 |       3 |   construction |          2 |            0 |            0\n",
            "                    fence |  13 |       4 |   construction |          2 |            0 |            0\n",
            "               guard rail |  14 |     255 |   construction |          2 |            0 |            1\n",
            "                   bridge |  15 |     255 |   construction |          2 |            0 |            1\n",
            "                   tunnel |  16 |     255 |   construction |          2 |            0 |            1\n",
            "                     pole |  17 |       5 |         object |          3 |            0 |            0\n",
            "                polegroup |  18 |     255 |         object |          3 |            0 |            1\n",
            "            traffic light |  19 |       6 |         object |          3 |            0 |            0\n",
            "             traffic sign |  20 |       7 |         object |          3 |            0 |            0\n",
            "               vegetation |  21 |       8 |         nature |          4 |            0 |            0\n",
            "                  terrain |  22 |       9 |         nature |          4 |            0 |            0\n",
            "                      sky |  23 |      10 |            sky |          5 |            0 |            0\n",
            "                   person |  24 |      11 |          human |          6 |            1 |            0\n",
            "                    rider |  25 |      12 |          human |          6 |            1 |            0\n",
            "                      car |  26 |      13 |        vehicle |          7 |            1 |            0\n",
            "                    truck |  27 |      14 |        vehicle |          7 |            1 |            0\n",
            "                      bus |  28 |      15 |        vehicle |          7 |            1 |            0\n",
            "                  caravan |  29 |     255 |        vehicle |          7 |            1 |            1\n",
            "                  trailer |  30 |     255 |        vehicle |          7 |            1 |            1\n",
            "                    train |  31 |      16 |        vehicle |          7 |            1 |            0\n",
            "               motorcycle |  32 |      17 |        vehicle |          7 |            1 |            0\n",
            "                  bicycle |  33 |      18 |        vehicle |          7 |            1 |            0\n",
            "            license plate |  -1 |      -1 |        vehicle |          7 |            0 |            1\n",
            "\n",
            "Example usages:\n",
            "ID of label 'car': 26\n",
            "Category of label with ID '26': vehicle\n",
            "Name of label with trainID '0': road\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "import os\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "from tensorflow.keras.layers import Conv2D,MaxPool2D,Dropout,UpSampling2D,Concatenate,Input,Softmax\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "kPQOLHp4NHKN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS=2\n",
        "BATCH_SIZE=10\n",
        "HEIGHT=256\n",
        "WIDTH=256\n",
        "N_CLASSES=13"
      ],
      "metadata": {
        "id": "Ibj-o6k2Ncx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LoadImage(name, path):\n",
        "    img = Image.open(os.path.join(path, name))\n",
        "    img = np.array(img)\n",
        "    \n",
        "    image = img[:,:256]\n",
        "    mask = img[:,256:]\n",
        "    \n",
        "    return image, mask\n",
        "\n",
        "\n",
        "def bin_image(mask):\n",
        "    bins = np.array([20, 40, 60, 80, 100, 120, 140, 160, 180, 200, 220, 240])\n",
        "    new_mask = np.digitize(mask, bins)\n",
        "    return new_mask\n",
        "\n",
        "def getSegmentationArr(image, classes, width=WIDTH, height=HEIGHT):\n",
        "    seg_labels = np.zeros((height, width, classes))\n",
        "    img = image[:, : , 0]\n",
        "\n",
        "    for c in range(classes):\n",
        "        seg_labels[:, :, c] = (img == c ).astype(int)\n",
        "    return seg_labels\n",
        "\n",
        "def give_color_to_seg_img(seg, n_classes=N_CLASSES):\n",
        "    \n",
        "    seg_img = np.zeros( (seg.shape[0],seg.shape[1],3) ).astype('float')\n",
        "    colors = sns.color_palette(\"hls\", n_classes)\n",
        "    \n",
        "    for c in range(n_classes):\n",
        "        segc = (seg == c)\n",
        "        seg_img[:,:,0] += (segc*( colors[c][0] ))\n",
        "        seg_img[:,:,1] += (segc*( colors[c][1] ))\n",
        "        seg_img[:,:,2] += (segc*( colors[c][2] ))\n",
        "\n",
        "    return(seg_img)\n",
        "\n",
        "classes = 13"
      ],
      "metadata": {
        "id": "bx_tv1JvNjhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"/input/cityscapes-image-pairs/cityscapes_data/train\""
      ],
      "metadata": {
        "id": "9fHNGfA9NrqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HTHJAhbkNu3k",
        "outputId": "f4233ebb-9778-43a0-9501-9f54e360b5a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/input/cityscapes-image-pairs/cityscapes_data/train'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "valid_folder = \"/input/cityscapes-image-pairs/cityscapes data/val\""
      ],
      "metadata": {
        "id": "PvJ5V6P2Ns9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_folder = \"/input/cityscapes-image-pairs/cityscapes_data/train\"\n",
        "valid_folder = \"/input/cityscapes-image-pairs/cityscapes_data/val\"\n",
        "\n",
        "num_of_training_samples = len(os.listdir(train_folder)) \n",
        "num_of_valid_samples = len(os.listdir(valid_folder))\n",
        "\n",
        "def DataGenerator(path, batch_size=BATCH_SIZE, classes=N_CLASSES):\n",
        "    files = os.listdir(path)\n",
        "    while True:\n",
        "        for i in range(0, len(files), batch_size):\n",
        "            batch_files = files[i : i+batch_size]\n",
        "            imgs=[]\n",
        "            segs=[]\n",
        "            for file in batch_files:\n",
        "                image, mask = LoadImage(file, path)\n",
        "                mask_binned = bin_image(mask)\n",
        "                labels = getSegmentationArr(mask_binned, classes)\n",
        "\n",
        "                imgs.append(image)\n",
        "                segs.append(labels)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "sYaFqIyRNkmi",
        "outputId": "3bf731de-bd2d-4d64-e2d7-ac5c84e2e7d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-09be759d1766>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mvalid_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/input/cityscapes-image-pairs/cityscapes_data/val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnum_of_training_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnum_of_valid_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/input/cityscapes-image-pairs/cityscapes_data/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CoCo dataset"
      ],
      "metadata": {
        "id": "6xkta9mucp4K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!cd data && git clone https://github.com/cocodataset/cocoapi\n",
        "!cd data/cocoapi/PythonAPI && make"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyhamhkMcVrV",
        "outputId": "5c9a6f7c-aedd-4fe2-dc09-bd039059ac6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'cocoapi'...\n",
            "remote: Enumerating objects: 975, done.\u001b[K\n",
            "remote: Total 975 (delta 0), reused 0 (delta 0), pack-reused 975\u001b[K\n",
            "Receiving objects: 100% (975/975), 11.72 MiB | 27.60 MiB/s, done.\n",
            "Resolving deltas: 100% (576/576), done.\n",
            "python setup.py build_ext --inplace\n",
            "running build_ext\n",
            "cythoning pycocotools/_mask.pyx to pycocotools/_mask.c\n",
            "/usr/local/lib/python3.7/dist-packages/Cython/Compiler/Main.py:369: FutureWarning: Cython directive 'language_level' not set, using 2 for now (Py2). This will change in a later release! File: /content/data/cocoapi/PythonAPI/pycocotools/_mask.pyx\n",
            "  tree = Parsing.p_module(s, pxd, full_module_name)\n",
            "building 'pycocotools._mask' extension\n",
            "creating build\n",
            "creating build/common\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c ../common/maskApi.c -o build/temp.linux-x86_64-3.7/../common/maskApi.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleDecode\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; v=!v; }}\n",
            "       \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:46:49:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "       for( k=0; k<R[i].cnts[j]; k++ ) *(M++)=v; \u001b[01;36m\u001b[Kv\u001b[m\u001b[K=!v; }}\n",
            "                                                 \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrPoly\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); x[k]=x[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:166:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) x[j]=(int)(scale*xy[j*2+0]+.5); \u001b[01;36m\u001b[Kx\u001b[m\u001b[K[k]=x[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kfor\u001b[m\u001b[K(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); y[k]=y[0];\n",
            "   \u001b[01;35m\u001b[K^~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:167:54:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kfor\u001b[m\u001b[K’\n",
            "   for(j=0; j<k; j++) y[j]=(int)(scale*xy[j*2+1]+.5); \u001b[01;36m\u001b[Ky\u001b[m\u001b[K[k]=y[0];\n",
            "                                                      \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "       \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(more) c |= 0x20; c+=48; s[p++]=c;\n",
            "       \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:212:27:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "       if(more) c |= 0x20; \u001b[01;36m\u001b[Kc\u001b[m\u001b[K+=48; s[p++]=c;\n",
            "                           \u001b[01;36m\u001b[K^\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleFrString\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:3:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "   \u001b[01;35m\u001b[Kwhile\u001b[m\u001b[K( s[m] ) m++; cnts=malloc(sizeof(uint)*m); m=0;\n",
            "   \u001b[01;35m\u001b[K^~~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:220:22:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kwhile\u001b[m\u001b[K’\n",
            "   while( s[m] ) m++; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K=malloc(sizeof(uint)*m); m=0;\n",
            "                      \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:5:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kthis ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’ clause does not guard... [\u001b[01;35m\u001b[K-Wmisleading-indentation\u001b[m\u001b[K]\n",
            "     \u001b[01;35m\u001b[Kif\u001b[m\u001b[K(m>2) x+=(long) cnts[m-2]; cnts[m++]=(uint) x;\n",
            "     \u001b[01;35m\u001b[K^~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:228:34:\u001b[m\u001b[K \u001b[01;36m\u001b[Knote: \u001b[m\u001b[K...this statement, but the latter is misleadingly indented as if it were guarded by the ‘\u001b[01m\u001b[Kif\u001b[m\u001b[K’\n",
            "     if(m>2) x+=(long) cnts[m-2]; \u001b[01;36m\u001b[Kcnts\u001b[m\u001b[K[m++]=(uint) x;\n",
            "                                  \u001b[01;36m\u001b[K^~~~\u001b[m\u001b[K\n",
            "\u001b[01m\u001b[K../common/maskApi.c:\u001b[m\u001b[K In function ‘\u001b[01m\u001b[KrleToBbox\u001b[m\u001b[K’:\n",
            "\u001b[01m\u001b[K../common/maskApi.c:141:31:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K‘\u001b[01m\u001b[Kxp\u001b[m\u001b[K’ may be used uninitialized in this function [\u001b[01;35m\u001b[K-Wmaybe-uninitialized\u001b[m\u001b[K]\n",
            "       if(j%2==0) xp=x; else if\u001b[01;35m\u001b[K(\u001b[m\u001b[Kxp<x) { ys=0; ye=h-1; }\n",
            "                               \u001b[01;35m\u001b[K^\u001b[m\u001b[K\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/numpy/core/include -I../common -I/usr/include/python3.7m -c pycocotools/_mask.c -o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -Wno-cpp -Wno-unused-function -std=c99\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/pycocotools\n",
            "x86_64-linux-gnu-gcc -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/../common/maskApi.o build/temp.linux-x86_64-3.7/pycocotools/_mask.o -o build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so\n",
            "copying build/lib.linux-x86_64-3.7/pycocotools/_mask.cpython-37m-x86_64-linux-gnu.so -> pycocotools\n",
            "rm -rf build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import skimage.io as io\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "4qB5DsSFcsol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "#tf.enable_eager_execution()\n",
        "print('TensorFlow version:', tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqD6Yby-cxsv",
        "outputId": "f6909df1-1d61-4390-ba20-189ed3422c3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "5fbD-meSczEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install livelossplot --quiet\n",
        "from livelossplot.tf_keras import PlotLossesCallback"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6Q_9g55c163",
        "outputId": "09526f61-80cb-4ee9-8bf0-9ecb606009f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 18.7 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 10.3 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 61 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 81 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 92 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 112 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 122 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 133 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 143 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 153 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 163 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 174 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 184 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████                            | 194 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 204 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 215 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 225 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 235 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████                           | 245 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 256 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 266 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 276 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 286 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 296 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 307 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 317 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 327 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 337 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████                         | 348 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 358 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 368 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 378 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████                        | 389 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 399 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 409 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 419 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 430 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 440 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 450 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 460 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 471 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 481 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 491 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 501 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 512 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 522 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 532 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 542 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 552 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 563 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 573 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 583 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 593 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 604 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 614 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 624 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 634 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 645 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 655 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 665 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 675 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 686 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 696 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 706 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 716 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 727 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 737 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 747 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 757 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 768 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 778 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 788 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 798 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 808 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 819 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 829 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 839 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 849 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 860 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 870 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 880 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 890 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 901 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 911 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 921 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 931 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 942 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 952 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 962 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 972 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 983 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 993 kB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.0 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.0 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.0 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.0 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.1 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.2 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.3 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.4 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.5 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.6 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 7.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.6 MB 7.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "COCO_ROOT = '../input/coco-2017-dataset/coco2017/'\n",
        "COCO_API_ROOT = './data/'\n",
        "import sys\n",
        "sys.path.insert(0, os.path.join(COCO_API_ROOT, 'cocoapi/PythonAPI'))\n",
        "from pycocotools.coco import COCO"
      ],
      "metadata": {
        "id": "e1uOqpfzdBIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset():\n",
        "\n",
        "    def crop_images(self, img, inp_size, random_crop=False):\n",
        "        shape = tf.shape(img)\n",
        "        pad = (\n",
        "            [0, tf.maximum(inp_size - shape[0], 0)],\n",
        "            [0, tf.maximum(inp_size - shape[1], 0)],\n",
        "            [0, 0],\n",
        "        )\n",
        "        img = tf.pad(img, pad)\n",
        "\n",
        "        if random_crop:\n",
        "            img = tf.image.random_crop(img, (inp_size, inp_size, shape[2]))\n",
        "        else: # central crop\n",
        "            shape = tf.shape(img)\n",
        "            ho = (shape[0] - inp_size) // 2\n",
        "            wo = (shape[1] - inp_size) // 2\n",
        "            img = img[ho:ho+inp_size, wo:wo+inp_size, :]\n",
        "\n",
        "        return img\n",
        "\n",
        "    def train_dataset(self, batch_size, epochs, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = True\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.shuffle(buffer_size=len(self.img_list))\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.repeat(epochs)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset\n",
        "\n",
        "    def val_dataset(self, batch_size, inp_size):\n",
        "\n",
        "        def item_to_images(item):\n",
        "            random_crop = False\n",
        "            img_combined = tf.py_function(self.read_images, [item], tf.uint8)\n",
        "            img_combined = self.crop_images(img_combined, inp_size, random_crop)\n",
        "\n",
        "            img = tf.cast(img_combined[...,:3], tf.float32) / np.float32(255.)\n",
        "            mask_class = tf.cast(img_combined[...,3:4], tf.float32)\n",
        "            return img, mask_class\n",
        "\n",
        "        dataset = tf.data.Dataset.from_tensor_slices(self.img_list)\n",
        "        dataset = dataset.map(item_to_images)\n",
        "        dataset = dataset.batch(batch_size, drop_remainder=True)\n",
        "\n",
        "        return dataset"
      ],
      "metadata": {
        "id": "e37asX6pdD-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class COCO_Dataset(Dataset):\n",
        "\n",
        "    def __init__(self, sublist, percent=1):\n",
        "        ann_file_fpath = os.path.join(COCO_ROOT, 'annotations', 'instances_'+sublist+'2017.json')\n",
        "        self.coco = COCO(ann_file_fpath)\n",
        "        self.cat_ids = self.coco.getCatIds(catNms=['person'])\n",
        "        self.img_list = self.coco.getImgIds(catIds=self.cat_ids)\n",
        "        assert percent > 0 and percent <= 1\n",
        "        self.img_list = random.sample(self.img_list, int(len(self.img_list) * percent))\n",
        "\n",
        "    def read_images(self, img_id):\n",
        "        img_id = int(img_id.numpy())\n",
        "        img_data = self.coco.loadImgs(img_id)[0]\n",
        "        img_fname = '/'.join(img_data['coco_url'].split('/')[-2:])\n",
        "\n",
        "        img = io.imread(os.path.join(COCO_ROOT, img_fname))\n",
        "        if len(img.shape) == 2:\n",
        "            img = np.tile(img[..., None], (1, 1, 3))\n",
        "\n",
        "        ann_ids = self.coco.getAnnIds(imgIds=img_data['id'], catIds=self.cat_ids, iscrowd=None)\n",
        "        anns = self.coco.loadAnns(ann_ids)\n",
        "        mask_class = np.zeros((img.shape[0], img.shape[1]), dtype=np.uint8)\n",
        "        for i in range(len(anns)):\n",
        "            mask_class += self.coco.annToMask(anns[i])\n",
        "        mask_class = (mask_class > 0).astype(np.uint8)\n",
        "\n",
        "        img_combined = np.concatenate([img, mask_class[..., None]], axis=2)\n",
        "\n",
        "        return img_combined"
      ],
      "metadata": {
        "id": "u46vd9smdILQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(image_size):\n",
        "    x = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    \n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
        "    out1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=2, activation='relu')(out1)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out2 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=2, activation='relu')(out2)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out3 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=2, activation='relu')(out3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out4 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', strides=2, activation='relu')(out4)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(1024, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    # out = tf.keras.layers.Conv2DTranspose(512, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.UpSampling2D(size=(2,2))(out)\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out4, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    # out = tf.keras.layers.Conv2DTranspose(256, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.UpSampling2D(size=(2,2))(out)\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out3, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    # out = tf.keras.layers.Conv2DTranspose(128, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.UpSampling2D(size=(2,2))(out)\n",
        "    out = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out2, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(out)\n",
        "\n",
        "    # out = tf.keras.layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.UpSampling2D(size=(2,2))(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.concat([out1, out], axis=3)\n",
        "\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(out)\n",
        "    out = tf.keras.layers.Conv2D(1, (3, 3), padding='same', activation='sigmoid')(out)\n",
        "    # out = (out > 0).astype(np.float16)\n",
        "    return tf.keras.Model(inputs=x, outputs=out)"
      ],
      "metadata": {
        "id": "wq8OFpKWdLGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ASPPBlock(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=6, padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=12, padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(256, (3, 3), dilation_rate=18, padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu')\n",
        "\n",
        "    def call(self, inp, is_training=False):\n",
        "        out1 = self.conv1(inp)\n",
        "        out2 = self.conv2(inp)\n",
        "        out3 = self.conv3(inp)\n",
        "        out4 = self.conv4(inp)\n",
        "        out = tf.concat([out1, out2, out3, out4], axis=3)\n",
        "        out = self.conv5(out)\n",
        "        return out\n",
        "    \n",
        "class ASPPNet(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.conv1 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')\n",
        "        self.conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv4 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')\n",
        "        self.conv5 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv6 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv7 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv8 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv9 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "        self.conv10 = tf.keras.layers.Conv2D(512, (3, 3), padding='same', activation='relu')\n",
        "\n",
        "        self.conv11 = tf.keras.layers.Conv2D(48, (1, 1), padding='same', activation='relu')\n",
        "        self.conv12 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv13 = tf.keras.layers.Conv2D(256, (3, 3), padding='same', activation='relu')\n",
        "        self.conv14 = tf.keras.layers.Conv2D(1, (1, 1), padding='same', activation=None)\n",
        "\n",
        "        self.maxpool = tf.keras.layers.MaxPooling2D((2, 2), (2, 2), padding='same')\n",
        "\n",
        "        self.aspp = ASPPBlock()\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.conv1(x)\n",
        "        out = self.conv2(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv3(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv5(out)\n",
        "        out = self.conv6(out)\n",
        "        out_enc_mid = out\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv7(out)\n",
        "        out = self.conv8(out)\n",
        "        out = self.maxpool(out)\n",
        "        out = self.conv9(out)\n",
        "        out = self.conv10(out)\n",
        "\n",
        "        out = self.aspp(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(out_enc_mid)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "\n",
        "        out_enc_mid = self.conv11(out_enc_mid)\n",
        "\n",
        "        out = tf.concat([out, out_enc_mid], axis=3)\n",
        "\n",
        "        out = self.conv12(out)\n",
        "        out = self.conv13(out)\n",
        "        out = self.conv14(out)\n",
        "\n",
        "        out = tf.image.resize(out, tf.shape(x)[1:3], tf.image.ResizeMethod.BILINEAR)\n",
        "        out = tf.nn.sigmoid(out)\n",
        "        return out\n",
        "\n",
        "def build_aspp_net_model(image_size):\n",
        "    model_ = ASPPNet()\n",
        "    inputs = tf.keras.layers.Input((image_size, image_size, 3))\n",
        "    outputs = model_(inputs)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "M3mjJqANdO8d"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}